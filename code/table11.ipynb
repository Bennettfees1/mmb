{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d6b98910",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.robust import scale, norms\n",
    "import pyreadstat\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "\n",
    "os.chdir('/Users/connorbrennan/OneDrive - The University of Chicago/mmb/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "081dbf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Variable           Description\n",
      "0             model         (first) model\n",
      "1              rule          (first) rule\n",
      "2           rule_tr           Taylor Rule\n",
      "3          rule_itr  Inertial Taylor Rule\n",
      "4            rule_g           Growth Rule\n",
      "..              ...                   ...\n",
      "129   stky_wg_nondx                  None\n",
      "130        stky_all                  None\n",
      "131  stky_pr_wg_ndx                  None\n",
      "132         ndx_all    P and W Indexation\n",
      "133          ln_neq       ln(Num. of Eq.)\n",
      "\n",
      "[134 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df, meta = pyreadstat.read_dta('derived/MMB_reg_format.dta')\n",
    "df_labels = pd.DataFrame({\n",
    "    \"Variable\": meta.column_names,\n",
    "    \"Description\": meta.column_labels\n",
    "})\n",
    "df = df.loc[df['y_timing_max'] < 99]\n",
    "df = df.loc[df['piq_timing_max'] < 99]\n",
    "\n",
    "print(df_labels)\n",
    "df['not_pr_ndx'] = 1 - df['pr_ndx']\n",
    "df['not_wg_ndx'] = 1 - df['wg_ndx']\n",
    "#df = df.loc[df['sacratio20'] < df['sacratio20'].quantile(0.98)]\n",
    "df_estimated = df.loc[df['estimated']==1]\n",
    "df_calibrated = df.loc[df['calibrated']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "534eb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_vars = ['rule_g', 'rule_itr', 'estimated']\n",
    "depvars_elasticities = ['IScurve20', 'infl_per_rr20', 'sacratio20']\n",
    "depvars_timing = ['y_timing_max', 'piq_timing_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e06611b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_tables(stepwise_regs, r2_values, depvars, horizons, var_labels, depvar_labels, outfile=None):\n",
    "    \"\"\"\n",
    "    Given a dictionary of stepwise regression results (stepwise_regs), a list of\n",
    "    dependent variables (depvars), and a list of horizons, generate nicely\n",
    "    formatted LaTeX tables with multirow rows for each variable, variable labels,\n",
    "    and lines at the bottom for R^2 or nobs.\n",
    "\n",
    "    We double backslash LaTeX commands to avoid Python interpreting escape chars.\n",
    "    \"\"\"\n",
    "    latex_pieces = []\n",
    "    for depvar in depvars:\n",
    "        # 2A) Identify which models belong to this dependent variable\n",
    "        these_models = {}\n",
    "        for h in horizons:\n",
    "            key = f\"{depvar}{h}\"\n",
    "            if key in stepwise_regs:\n",
    "                these_models[h] = stepwise_regs[key]\n",
    "\n",
    "        # If no models found for this depvar, skip\n",
    "        if not these_models:\n",
    "            continue\n",
    "\n",
    "        # 2B) Collect the union of all variable names across these models\n",
    "        varset = set()\n",
    "        for h, model in these_models.items():\n",
    "            varset = varset.union(model.params.index)\n",
    "        # Sort them in a consistent order, but keep 'Intercept' on top if you prefer\n",
    "        varlist = sorted(varset, key=lambda v: (v != 'Intercept', v))\n",
    "\n",
    "        # 2C) Start building the LaTeX string\n",
    "        latex_str = []\n",
    "        latex_str.append(\"\\\\begin{table}[h!]\")\n",
    "        latex_str.append(\"\\\\centering\")\n",
    "        latex_str.append(\"\\\\resizebox{0.8\\\\textwidth}{!}{%\")  # Optional scaling\n",
    "        latex_str.append(\"\\\\begin{tabular}{l\" + \"c\"*len(horizons) + \"}\")\n",
    "        latex_str.append(\"\\\\hline\")\n",
    "\n",
    "        # 2D) First row: label the dependent variable, spanning all columns\n",
    "        latex_str.append(\n",
    "            f\"\\\\multicolumn{{{len(horizons)+1}}}{{l}}{{\\\\textbf{{Dependent Variable: {depvar_labels[depvar]}}}}} \\\\\\\\\"\n",
    "        )\n",
    "        latex_str.append(\"\\\\hline\")\n",
    "\n",
    "        # 2E) Print horizon labels, e.g. & (20) & (40) & (60)\n",
    "        horizon_header = \"\\\\textbf{{Horizon}} & \" + \" & \".join([f\"{h}\" for h in horizons]) + \" \\\\\\\\\"\n",
    "        latex_str.append(horizon_header)\n",
    "        latex_str.append(\"\\\\hline\")\n",
    "\n",
    "        # 2F) For each variable, produce two rows:\n",
    "        #     (1) multirow w/ var name + coefficients\n",
    "        #     (2) blank first cell + std errors\n",
    "        for var in varlist:\n",
    "            # Build dict for param/std_err across horizons\n",
    "            coeffs = []\n",
    "            std_errs = []\n",
    "            for h in horizons:\n",
    "                model = these_models.get(h, None)\n",
    "                if model is not None and var in model.params.index:\n",
    "                    param = model.params[var]\n",
    "                    pval  = model.pvalues[var]\n",
    "                    stderr= model.bse[var]\n",
    "\n",
    "                    coeffs.append(format_coef(param, pval))\n",
    "                    std_errs.append(format_se(stderr))\n",
    "                else:\n",
    "                    coeffs.append(\"\")\n",
    "                    std_errs.append(\"\")\n",
    "\n",
    "            # 2G) Resolve variable label if available, otherwise default\n",
    "            if var in var_labels:\n",
    "                varname_latex = var_labels[var]\n",
    "            else:\n",
    "                varname_latex = var\n",
    "            # Escape underscores for LaTeX\n",
    "            varname_latex = varname_latex.replace(\"_\", \"\\\\_\")\n",
    "\n",
    "            # Multirow lines\n",
    "            line1 = f\"\\\\multirow{{2}}{{*}}{{{varname_latex}}} & \" + \" & \".join(coeffs) + \" \\\\\\\\\"\n",
    "            line2 = \" & \" + \" & \".join(std_errs) + \" \\\\\\\\\"\n",
    "\n",
    "            latex_str.append(line1)\n",
    "            latex_str.append(line2)\n",
    "\n",
    "        # 2H) Now we add lines for number of observations, and (optionally) R^2\n",
    "        #     We'll build them across the horizons, e.g.: Observations & n1 & n2 & n3\n",
    "        #     For RLM, there's no built-in R^2, but we can just show placeholders\n",
    "        latex_str.append(\"\\\\hline\")\n",
    "\n",
    "        # Observations line\n",
    "        nobs_list = []\n",
    "        for h in horizons:\n",
    "            model = these_models.get(h, None)\n",
    "            if model is not None:\n",
    "                nobs_list.append(str(int(model.nobs)))\n",
    "            else:\n",
    "                nobs_list.append(\"\")\n",
    "        latex_str.append(\"Observations & \" + \" & \".join(nobs_list) + \" \\\\\\\\\")\n",
    "\n",
    "        # R-squared (placeholder or a custom statistic)\n",
    "        # For RLM there's no rsquared by default, so we just show an example row:\n",
    "        # If you compute your own pseudo-R^2, replace \"... \" with that value\n",
    "        r2_list = []\n",
    "        for h in horizons:\n",
    "            r2 = r2_values.get(f'{depvar}{h}', None)\n",
    "            if r2 is not None:\n",
    "                # placeholder; replace with something like \"f'{model_custom_r2:.3f}'\"\n",
    "                r2_list.append(str(round(r2,3)))\n",
    "            else:\n",
    "                r2_list.append(\"\")\n",
    "        latex_str.append(\"$R^2$ from Final Weights& \" + f'{\" & \".join(r2_list)}' + \" \\\\\\\\\")\n",
    "\n",
    "        # 2I) Wrap up\n",
    "        latex_str.append(\"\\\\hline\")\n",
    "        latex_str.append(\"\\\\end{tabular}\")\n",
    "        latex_str.append(\"}\")  # Closes \\\\resizebox\n",
    "        latex_str.append(f\"\\\\caption{{Stepwise RLM results for {depvar_labels[depvar]}}}\")\n",
    "        latex_str.append(\"\\\\end{table}\")\n",
    "        latex_str.append(\"\\\\newpage\")\n",
    "\n",
    "        # Print the LaTeX code for this table\n",
    "        table_code = \"\\n\".join(latex_str)\n",
    "        latex_pieces.append(table_code)\n",
    "        #print(table_code)\n",
    "        #print(\"\\n\\n\")  # some space after each table\n",
    "    \n",
    "    all_tables = \"\\n\\n\".join(latex_pieces)\n",
    "    if outfile is not None:\n",
    "        with open(outfile, \"w\") as f:\n",
    "            f.write(all_tables)\n",
    "        print(f\"Saved all tables to {outfile}\")\n",
    "    else:\n",
    "        print(all_tables)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def generate_latex_master_table(stepwise_regs, r2_values, depvars,\n",
    "                                var_labels, depvar_labels, outfile=None,\n",
    "                                table_caption=\"Regression results (all models)\"):\n",
    "    \"\"\"\n",
    "    Build ONE LaTeX table with columns for each depvar model.\n",
    "    Rows are the union of variables across all models. Blank cells where\n",
    "    a variable didn't enter. Two rows per variable: coef row, then std. error row.\n",
    "\n",
    "    Requires helper functions:\n",
    "        - format_coef(beta, pval) -> str\n",
    "        - format_se(stderr) -> str\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Determine which depvars exist in results\n",
    "    columns = []\n",
    "    for depvar in depvars:\n",
    "        if depvar in stepwise_regs:\n",
    "            columns.append(depvar)\n",
    "\n",
    "    if not columns:\n",
    "        print(\"No models found in stepwise_regs for the provided depvars.\")\n",
    "        return\n",
    "\n",
    "    # 2) Union of all variable names across all models\n",
    "    varset = set()\n",
    "    for depvar in columns:\n",
    "        varset |= set(stepwise_regs[depvar].params.index)\n",
    "\n",
    "    # Keep Intercept/const on top, then alphabetical\n",
    "    varlist = sorted(varset, key=lambda v: (v not in (\"Intercept\",\"const\"), v))\n",
    "\n",
    "    # 3) Build LaTeX\n",
    "    latex = []\n",
    "    latex.append(\"\\\\begin{table}[h!]\")\n",
    "    latex.append(\"\\\\centering\")\n",
    "    latex.append(\"\\\\resizebox{0.95\\\\textwidth}{!}{%\")\n",
    "    latex.append(\"\\\\setlength{\\\\tabcolsep}{8pt}%\")\n",
    "    latex.append(\"\\\\begin{tabular}{l\" + \"c\"*len(columns) + \"}\")\n",
    "    latex.append(\"\\\\hline\")\n",
    "\n",
    "    # 4) Header row with depvar names\n",
    "    header_cells = [\"\\\\textbf{Variable}\"]\n",
    "    for depvar in columns:\n",
    "        label = depvar_labels.get(depvar, depvar).replace(\"_\", \"\\\\_\")\n",
    "        header_cells.append(f\"\\\\textbf{{{label}}}\")\n",
    "    latex.append(\" & \".join(header_cells) + \" \\\\\\\\\")\n",
    "    latex.append(\"\\\\hline\")\n",
    "\n",
    "    # 5) Body: each variable, coef row + se row\n",
    "    for var in varlist:\n",
    "        coef_cells = [var_labels.get(var, var).replace(\"_\", \"\\\\_\")]\n",
    "        for depvar in columns:\n",
    "            model = stepwise_regs[depvar]\n",
    "            if var in model.params.index:\n",
    "                beta = model.params[var]\n",
    "                pval = model.pvalues.get(var, None)\n",
    "                coef_cells.append(format_coef(beta, pval))\n",
    "            else:\n",
    "                coef_cells.append(\"\")\n",
    "        latex.append(\" & \".join(coef_cells) + \" \\\\\\\\\")\n",
    "\n",
    "        se_cells = [\"\"]\n",
    "        for depvar in columns:\n",
    "            model = stepwise_regs[depvar]\n",
    "            if var in model.params.index:\n",
    "                se = model.bse.get(var, None)\n",
    "                se_cells.append(format_se(se))\n",
    "            else:\n",
    "                se_cells.append(\"\")\n",
    "        latex.append(\" & \".join(se_cells) + \" \\\\\\\\\")\n",
    "\n",
    "    latex.append(\"\\\\hline\")\n",
    "\n",
    "    # 6) Observations row\n",
    "    obs_cells = [\"Observations\"]\n",
    "    for depvar in columns:\n",
    "        model = stepwise_regs[depvar]\n",
    "        obs_cells.append(str(int(getattr(model, \"nobs\", \"\")) or \"\"))\n",
    "    latex.append(\" & \".join(obs_cells) + \" \\\\\\\\\")\n",
    "\n",
    "    # 7) R^2 row\n",
    "    r2_cells = [\"$R^2$\"]\n",
    "    for depvar in columns:\n",
    "        r2 = r2_values.get(depvar, None)\n",
    "        r2_cells.append(\"\" if r2 is None else f\"{r2:.3f}\")\n",
    "    latex.append(\" & \".join(r2_cells) + \" \\\\\\\\\")\n",
    "\n",
    "    latex.append(\"\\\\hline\")\n",
    "    latex.append(\"\\\\end{tabular}\")\n",
    "    latex.append(\"}% end resizebox\")\n",
    "    latex.append(f\"\\\\caption{{{table_caption}}}\")\n",
    "    latex.append(\"\\\\end{table}\")\n",
    "    latex.append(\"\\\\newpage\")\n",
    "\n",
    "    table_code = \"\\n\".join(latex)\n",
    "\n",
    "    if outfile is not None:\n",
    "        with open(outfile, \"w\") as f:\n",
    "            f.write(table_code)\n",
    "        print(f\"Saved master table to {outfile}\")\n",
    "    else:\n",
    "        print(table_code)\n",
    "\n",
    "\n",
    "\n",
    "def format_coef(param, pval):\n",
    "    \"\"\"\n",
    "    Formats the coefficient with 3 decimal places plus significance stars.\n",
    "    \"\"\"\n",
    "    return f\"{param:.3f}{significance_stars(pval)}\"\n",
    "\n",
    "\n",
    "\n",
    "def format_se(std_err):\n",
    "    \"\"\"\n",
    "    Formats the standard error in parentheses, with 3 decimal places.\n",
    "    \"\"\"\n",
    "    return f\"({std_err:.3f})\"\n",
    "\n",
    "\n",
    "\n",
    "def significance_stars(pval):\n",
    "    if pval < 0.01:\n",
    "        return \"***\"\n",
    "    elif pval < 0.05:\n",
    "        return \"**\"\n",
    "    elif pval < 0.10:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def get_r2(orig_reg, depvar, data):\n",
    "    \"\"\"\n",
    "    Unified R^2:\n",
    "      - RLM: adj. R^2 via WLS with final weights.\n",
    "      - GLM (Poisson / NegBin): deviance-based pseudo-R^2 if available,\n",
    "        else McFadden's pseudo-R^2.\n",
    "      - Fallback: OLS adj. R^2 or NaN.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import statsmodels.api as sm\n",
    "    import statsmodels.formula.api as smf\n",
    "    from patsy import dmatrices\n",
    "\n",
    "    # ---- GLM path (Poisson / NegBin etc.) ----\n",
    "    # GLMResults have .model.family, .deviance, .null_deviance, .llf, .llnull\n",
    "    if hasattr(orig_reg, \"model\") and hasattr(orig_reg.model, \"family\"):\n",
    "        res = orig_reg\n",
    "        r2_dev = None\n",
    "        r2_mcf = None\n",
    "\n",
    "        null_dev = getattr(res, \"null_deviance\", None)\n",
    "        dev = getattr(res, \"deviance\", None)\n",
    "        if null_dev is not None and dev is not None and np.isfinite(null_dev) and null_dev > 0:\n",
    "            r2_dev = 1.0 - (dev / null_dev)\n",
    "\n",
    "        llnull = getattr(res, \"llnull\", None)\n",
    "        llf = getattr(res, \"llf\", None)\n",
    "        if llnull is not None and llf is not None and np.isfinite(llnull) and llnull != 0:\n",
    "            r2_mcf = 1.0 - (llf / llnull)\n",
    "\n",
    "        # Prefer deviance-based; fallback to McFadden\n",
    "        if r2_dev is not None and np.isfinite(r2_dev):\n",
    "            return float(r2_dev)\n",
    "        if r2_mcf is not None and np.isfinite(r2_mcf):\n",
    "            return float(r2_mcf)\n",
    "        return np.nan\n",
    "\n",
    "    # ---- RLM path (your robust linear models) ----\n",
    "    # Rebuild WLS with final weights to compute adj. R^2 (what you had before).\n",
    "    if hasattr(orig_reg, \"weights\") and hasattr(orig_reg, \"params\"):\n",
    "        terms = [t for t in orig_reg.params.index if t not in (\"Intercept\", \"const\")]\n",
    "        formula_str = f\"{depvar} ~ \" + (\" + \".join(terms) if terms else \"1\")\n",
    "\n",
    "        y, X = dmatrices(formula_str, data=data, return_type=\"dataframe\")\n",
    "        valid_index = X.index\n",
    "\n",
    "        # orig_reg.weights may be array-like; make a Series aligned to valid_index\n",
    "        if isinstance(orig_reg.weights, pd.Series):\n",
    "            weights_series = orig_reg.weights.loc[valid_index]\n",
    "        else:\n",
    "            weights_series = pd.Series(np.asarray(orig_reg.weights), index=valid_index)\n",
    "\n",
    "        df_sub = data.loc[valid_index]\n",
    "        wls_reg = smf.wls(formula_str, data=df_sub, weights=weights_series).fit(cov=\"H1\")\n",
    "        return float(wls_reg.rsquared_adj)\n",
    "\n",
    "    # ---- Fallback: OLS adj. R^2 using available params as terms ----\n",
    "    try:\n",
    "        terms = [t for t in orig_reg.params.index if t not in (\"Intercept\", \"const\")]\n",
    "        formula_str = f\"{depvar} ~ \" + (\" + \".join(terms) if terms else \"1\")\n",
    "        ols_reg = smf.ols(formula_str, data=data).fit()\n",
    "        return float(ols_reg.rsquared_adj)\n",
    "    except Exception:\n",
    "        return float(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b3271eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "depvar_labels = {'IScurve20': 'IS Curve',\n",
    "                 'infl_per_rr20': 'Pi Curve',\n",
    "                 'sacratio20': 'Sacrifice Ratio',\n",
    "                 'y_timing_max': 'y-timing ',\n",
    "                 'piq_timing_max': 'pi_timing'}\n",
    "\n",
    "\n",
    "\n",
    "var_labels = {\n",
    "    'Intercept': \"Constant\",\n",
    "    'rule_g': \"Rule: Growth\",\n",
    "    'rule_itr': \"Rule: Inert. Taylor\",\n",
    "    'stky_pr_calvo': \"Sticky Prices (Calvo)\",\n",
    "    'stky_pr_rotemberg': \"Sticky Prices (Rotemberg)\", \n",
    "    'stky_pr_other': \"Sticky Prices (Other)\", \n",
    "    'stky_wg': \"Sticky Wages\", \n",
    "    'pr_ndx': \"Price Idx\", \n",
    "    'wg_ndx': \"Wage Idx.\", \n",
    "    'wg_ndx_prprice': \"Wage Idx. (Prev. Price)\", \n",
    "    'wg_ndx_mult': \"Wage Idx. (Mult. Price)\", \n",
    "    'wg_ndx_other': \"Wage Idx. (Other)\",\n",
    "\n",
    "    # interactions (nomrig)\n",
    "    'stky_pr_calvo:pr_ndx': \"Sticky Price (Calvo) $\\\\times$ Price Idx.\", \n",
    "    'stky_pr_rotemberg:pr_ndx': \"Sticky Price (Rotemberg) $\\\\times$ Price Idx.\", \n",
    "    'stky_pr_other:pr_ndx': \"Sticky Price (Other) $\\\\times$ Price Idx.\",\n",
    "    'stky_wg:wg_ndx': \"Sticky Wages $\\\\times$ Wage Idx.\", \n",
    "    'stky_wg:wg_ndx_prprice': \"Sticky Wages $\\\\times$ Wage Idx. (Prev. Price)\", \n",
    "    'stky_wg:wg_ndx_mult': \"Sticky Wages $\\\\times$ Wage Idx. (Mult. Price)\", \n",
    "    'stky_wg:wg_ndx_other': \"Sticky Wages $\\\\times$ Wage Idx. (Other)\",\n",
    "\n",
    "    # added missing nomrig\n",
    "    'stky_pr': \"Sticky Prices\",\n",
    "    'stky_wg': \"Sticky Wages\",\n",
    "    'stky_pr:pr_ndx': \"Sticky Prices $\\\\times$ Price Idx.\",\n",
    "    'stky_wg:wg_ndx': \"Sticky Wages $\\\\times$ Wage Idx.\",\n",
    "    'stky_pr:not_pr_ndx': \"Sticky Prices $\\\\times$ Not Price Idx.\",\n",
    "    'stky_wg:not_wg_ndx': \"Sticky Wages $\\\\times$ Not Wage Idx.\",\n",
    "    'stky_pr:wg_ndx': \"Sticky Prices $\\\\times$ Wage Idx.\",\n",
    "    'stky_wg:pr_ndx': \"Sticky Wages $\\\\times$ Price Idx.\",\n",
    "    'stky_pr:not_wg_ndx': \"Sticky Prices $\\\\times$ Not Wage Idx.\",\n",
    "    'stky_wg:not_pr_ndx': \"Sticky Wages $\\\\times$ Not Price Idx.\",\n",
    "\n",
    "    # real rigidities\n",
    "    'wlth': \"Wealth Channel\",\n",
    "    'ntwrth': \"Net Worth Channel\",\n",
    "    'bnkcrdit': \"Bank Credit Channel\",\n",
    "    'open': \"Open Economy\",\n",
    "    'learning': \"Learning Channel\",\n",
    "\n",
    "    'wlth:ntwrth': \"Wealth $\\\\times$ Net Worth\",\n",
    "    'wlth:bnkcrdit': \"Wealth $\\\\times$ Bank Credit\",\n",
    "    'wlth:open': \"Wealth $\\\\times$ Open Economy\",\n",
    "    'wlth:learning': \"Wealth $\\\\times$ Learning\",\n",
    "    'ntwrth:bnkcrdit': \"Net Worth $\\\\times$ Bank Credit\",\n",
    "    'ntwrth:open': \"Net Worth $\\\\times$ Open Economy\",\n",
    "    'ntwrth:learning': \"Net Worth $\\\\times$ Learning\",\n",
    "    'bnkcrdit:open': \"Bank Credit $\\\\times$ Open Economy\",\n",
    "    'bnkcrdit:learning': \"Bank Credit $\\\\times$ Learning\",\n",
    "    'open:learning': \"Open Economy $\\\\times$ Learning\",\n",
    "\n",
    "    # non-modeling vars\n",
    "    'estimated': \"Estimated\", \n",
    "    'est_early': \"Early Data\", \n",
    "    'est_late': \"Late Data\", \n",
    "    'vint_early': \"Early Vintage\", \n",
    "    'vint_mid': \"Mid Vintage\", \n",
    "    'vint_late': \"Late Vintage\", \n",
    "    'cb_authors_ext': \"Central Bank Author\", \n",
    "    'ln_neq': \"$\\\\log(\\\\text{Num. of Eqs.})$\",\n",
    "\n",
    "    # interactions (nonmod)\n",
    "    'cb_authors_ext:estimated': \"Central Bank Author $\\\\times$ Estimated\",\n",
    "    'cb_authors_ext:ln_neq': \"Central Bank Author $\\\\times$ $\\\\log($Num. of Eqs.$)$\",\n",
    "    'cb_authors_ext:vint_early': \"Central Bank Author $\\\\times$ Early Vintage\",\n",
    "    'cb_authors_ext:vint_mid': \"Central Bank Author $\\\\times$ Mid Vintage\",\n",
    "    'cb_authors_ext:vint_late': \"Central Bank Author $\\\\times$ Late Vintage\",\n",
    "    'cb_authors_ext:est_early': \"Central Bank Author $\\\\times$ Early Data\",\n",
    "    'cb_authors_ext:est_late': \"Central Bank Author $\\\\times$ Late Data\",\n",
    "\n",
    "    'estimated:ln_neq': \"Estimated $\\\\times$ $\\\\log($Num. of Eqs.$)$\",\n",
    "    'estimated:vint_early': \"Estimated $\\\\times$ Early Vintage\",\n",
    "    'estimated:vint_mid': \"Estimated $\\\\times$ Mid Vintage\",\n",
    "    'estimated:vint_late': \"Estimated $\\\\times$ Late Vintage\",\n",
    "    'estimated:est_early': \"Estimated $\\\\times$ Early Data\",\n",
    "    'estimated:est_late': \"Estimated $\\\\times$ Late Data\",\n",
    "\n",
    "    'ln_neq:vint_early': \"$\\\\log($Num. of Eqs.$)$ $\\\\times$ Early Vintage\",\n",
    "    'ln_neq:vint_mid': \"$\\\\log($Num. of Eqs.$)$ $\\\\times$ Mid Vintage\",\n",
    "    'ln_neq:vint_late': \"$\\\\log($Num. of Eqs.$)$ $\\\\times$ Late Vintage\",\n",
    "    'ln_neq:est_early': \"$\\\\log($Num. of Eqs.$)$ $\\\\times$ Early Data\",\n",
    "    'ln_neq:est_late': \"$\\\\log($Num. of Eqs.$)$ $\\\\times$ Late Data\",\n",
    "\n",
    "    'vint_early:est_early': \"Early Vintage $\\\\times$ Early Data\",\n",
    "    'vint_early:est_late': \"Early Vintage $\\\\times$ Late Data\",\n",
    "    'vint_mid:est_early': \"Mid Vintage $\\\\times$ Early Data\",\n",
    "    'vint_mid:est_late': \"Mid Vintage $\\\\times$ Late Data\",\n",
    "    'vint_late:est_early': \"Late Vintage $\\\\times$ Early Data\",\n",
    "    'vint_late:est_late': \"Late Vintage $\\\\times$ Late Data\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c71fc25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_formula(vars_, depvar, fixed_vars = fixed_vars):\n",
    "    rhs = []\n",
    "    if vars_:\n",
    "        rhs.append(\"+\".join(vars_))\n",
    "    if fixed_vars:\n",
    "        rhs.append(\"+\".join(fixed_vars))\n",
    "    return f\"{depvar} ~ \" + (\" + \".join(rhs) if rhs else \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a0159263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wooldridge_overdispersion_glm(\n",
    "    df: pd.DataFrame,\n",
    "    dep: str,\n",
    "    regressors: List[str],\n",
    "    controls: Optional[List[str]] = fixed_vars,\n",
    "    subset: Optional[pd.Series] = None,\n",
    "    time_limit_col: Optional[str] = None,\n",
    "    time_limit_val: Optional[float] = None,\n",
    "    alpha_floor: float = 1e-8,\n",
    "    robust_cov: str = \"HC0\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Wooldridge (1997) overdispersion test + choose Poisson vs NB2 (QMLE with robust SEs).\n",
    "    Uses Patsy formulas so interaction terms like 'a:b' are constructed properly.\n",
    "    Returns the *final* fitted results object (Poisson or NB2) for your later use.\n",
    "    \"\"\"\n",
    "    # Build mask analogous to Stata's if-conditions\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    if subset is not None:\n",
    "        mask &= subset.astype(bool)\n",
    "    if (time_limit_col is not None) and (time_limit_val is not None):\n",
    "        mask &= df[time_limit_col] < time_limit_val\n",
    "\n",
    "    # Build formula string (this already appends your fixed_vars)\n",
    "    formula = build_formula(regressors, dep, fixed_vars=controls)\n",
    "\n",
    "    # Use Patsy to build y, X with interactions handled\n",
    "    data_sub = df.loc[mask].copy()\n",
    "    y, X = dmatrices(formula, data=data_sub, return_type='dataframe')\n",
    "\n",
    "    # --- Step 1: Robust Poisson GLM\n",
    "    poisson_model = sm.GLM(y, X, family=sm.families.Poisson())\n",
    "    pois_res = poisson_model.fit(cov_type=robust_cov)\n",
    "\n",
    "    # μ-hat\n",
    "    mu_hat = pois_res.fittedvalues.squeeze()\n",
    "\n",
    "    # --- Step 2: Wooldridge auxiliary regression (no constant)\n",
    "    aux_dep = ((y.squeeze() - mu_hat) ** 2) - y.squeeze()\n",
    "    mu2 = mu_hat ** 2\n",
    "    aux_model = sm.OLS(aux_dep, mu2)  # nocons\n",
    "    aux_res = aux_model.fit(cov_type=robust_cov)\n",
    "    alpha_hat = float(aux_res.params.squeeze())\n",
    "    p_over = float(aux_res.pvalues.squeeze())\n",
    "\n",
    "    # --- Step 3: Choose final model\n",
    "    if np.isnan(alpha_hat):\n",
    "        return pois_res\n",
    "\n",
    "    if p_over < 0.05:\n",
    "        alpha_use = max(alpha_hat, alpha_floor)\n",
    "        nb_fam = sm.families.NegativeBinomial(alpha=alpha_use)  # Var = μ + α μ²\n",
    "        nb_model = sm.GLM(y, X, family=nb_fam)\n",
    "        final_res = nb_model.fit(cov_type=robust_cov)\n",
    "        return final_res\n",
    "    else:\n",
    "        return pois_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db6c437",
   "metadata": {},
   "source": [
    "# Bill's Way -- only have signficantly estimated variables enter in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "34a5c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "indepvars = ['stky_wg:wg_ndx', 'stky_wg:not_wg_ndx', 'pr_ndx', \n",
    "                          'ntwrth:bnkcrdit', 'wlth:ntwrth', 'wlth:open', 'ntwrth', 'wlth',\n",
    "                          'cb_authors_ext', 'vint_early', 'vint_mid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "409515dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved master table to ../output/table11/billway.txt\n"
     ]
    }
   ],
   "source": [
    "regs = {}\n",
    "r2s = {}\n",
    "\n",
    "for dvar in depvars_elasticities:\n",
    "    y, X = dmatrices(build_formula(indepvars, dvar), data=df, return_type='dataframe')\n",
    "    rank_X, cond_num = np.linalg.matrix_rank(X), np.linalg.cond(X)\n",
    "    if (rank_X < X.shape[1]) or (cond_num > 1000):\n",
    "        raise('Collinearity detected!')\n",
    "\n",
    "    regs[f'{dvar}'] = smf.rlm(\n",
    "                build_formula(indepvars, dvar),\n",
    "                M = norms.TukeyBiweight(c=4.685),\n",
    "                data = df\n",
    "            ).fit(\n",
    "                scale_est = scale.HuberScale(),\n",
    "                update_scale = True,\n",
    "                cov = 'H1',\n",
    "                conv='coefs'\n",
    "            )\n",
    "    r2s[f'{dvar}'] = get_r2(regs[f'{dvar}'], f'{dvar}', df)\n",
    "    \n",
    "\n",
    "\n",
    "for dvar in depvars_timing:\n",
    "    regs[f'{dvar}'] = wooldridge_overdispersion_glm(df, f'{dvar}', indepvars)\n",
    "    r2s[f'{dvar}'] = get_r2(regs[f'{dvar}'], f'{dvar}', df)\n",
    "\n",
    "generate_latex_master_table(regs, r2s, depvars_elasticities + depvars_timing, var_labels, depvar_labels, '../output/table11/billway.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591451f7",
   "metadata": {},
   "source": [
    "# Connor's way \n",
    "If we do want to keep the RHSs the same, I believe what we have for Table 11 is practically fine. However, I believe we should also add net worth effect and open as their own regressors as is standard when doing interactions. This is going to lead into my final point below…\n",
    "\n",
    "When including bivariate interaction terms, does it make sense to include only the multiplication and not the individual variables themselves? That is, not just including, say “Bank Credit *Net Worth” but also including “Net Worth” and “Bank Credit” on their own. Unless we have a good theoretical justification for why we should not include those individual terms, I believe we should include those in all regressions involving interactions in Table 11. Therefore, my specification would be to simply include bank credit, open, wealth, and net worth as their own regressors in Table 11. These suggestions are based off my took of Tables 7-10 and what stepwise suggests should work best.\n",
    "\n",
    "My justification for Table 11 would be that, after examining Tables 7-10, we include variables that appear important across our three categories to see how much variation we can explain within the responses of these macro models. And it is not much, which is our main selling point for this section. Then we can say that “in general, models of a middle vintage are characterized as… while models with central bank authors are characterized as…”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ffac4d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "indepvars = ['stky_wg:wg_ndx', 'stky_wg:not_wg_ndx', 'pr_ndx',\n",
    "            'ntwrth:bnkcrdit', 'wlth:open', 'ntwrth', 'wlth', 'bnkcrdit', 'open',\n",
    "            'cb_authors_ext', 'vint_mid', 'vint_late', 'cb_authors_ext:vint_late',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1a364deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved master table to ../output/table11/connorway.txt\n"
     ]
    }
   ],
   "source": [
    "regs = {}\n",
    "r2s = {}\n",
    "\n",
    "for dvar in depvars_elasticities:\n",
    "    y, X = dmatrices(build_formula(indepvars, dvar), data=df, return_type='dataframe')\n",
    "    rank_X, cond_num = np.linalg.matrix_rank(X), np.linalg.cond(X)\n",
    "    if (rank_X < X.shape[1]) or (cond_num > 1000):\n",
    "        raise('Collinearity detected!')\n",
    "\n",
    "    regs[f'{dvar}'] = smf.rlm(\n",
    "                build_formula(indepvars, dvar),\n",
    "                M = norms.TukeyBiweight(c=4.685),\n",
    "                data = df\n",
    "            ).fit(\n",
    "                scale_est = scale.HuberScale(),\n",
    "                update_scale = True,\n",
    "                cov = 'H1',\n",
    "                conv='coefs'\n",
    "            )\n",
    "    r2s[f'{dvar}'] = get_r2(regs[f'{dvar}'], f'{dvar}', df)\n",
    "    \n",
    "\n",
    "\n",
    "for dvar in depvars_timing:\n",
    "    regs[f'{dvar}'] = wooldridge_overdispersion_glm(df, f'{dvar}', indepvars)\n",
    "    r2s[f'{dvar}'] = get_r2(regs[f'{dvar}'], f'{dvar}', df)\n",
    "\n",
    "generate_latex_master_table(regs, r2s, depvars_elasticities + depvars_timing, var_labels, depvar_labels, '../output/table11/connorway.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "323f3fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11059907834101383"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['open'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326492af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
